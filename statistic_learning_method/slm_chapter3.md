# 1 $k$ 近邻法
- $k$ 近邻法的三个基本要素： $k$值的选择， 距离度量， 分类决策规则
## 1.1 $k$ 近邻算法
**输入**： 训练数据集
$$
T = \{ (x_1, y_1), (x_2, y_2),..., (x_N, y_N)\}
$$
其中， $x_i \in \mathcal{X}  \subseteq R^n$为实例的特征向量， $y_i \in  \mathcal{Y} ＝\{c_1， c_2,…,c_K\}$ 为实例的类别， $i＝1,2,…,N$； 实例特征向量$x$；
**输出**： 实例$x$所属的类$y$.
(1)  根据给定的距离度量， 在训练集$T$中找出与$x$最邻近的$k$个点， 涵盖这$k$个点的$x$的邻域记作$N_k(x)$；
(2) 在$N_k(x)$中根据分类决策规则（如多数表决） 决定$x$的类别$y$：
$$
y = \arg \max\limits_{c_j} \sum\limits_{x_i \in N_k (x)} I(y_i = c_j), i= 1,2,..,N; j=1,2,...,K
$$
式中$I$为指示函数，即当$y_i = c_j$时$I$为1， 否则为0。

(3) 最近邻算法：取 $k=1$ 时

## 1.2 距离度量
- $L_p$ 距离
    $$
    L_p (x_i, x_j) = \left( \sum\limits_{l=1}^n | x_i^{(l)} -x_j^{(l)} |^p \right)^{\frac{1}{p}}
    $$
	这里的$p\geq 1$,当$p​$取不同的值的时候会得到不同的距离。
	- 当 $p=2$时， 称为欧式距离（Euclidean distance）
	- 当 $p=1$时， 称为曼哈顿距离（Manhattan distance）
	- 当 $p=\infty$时， 取各个坐标距离的最大值，即 $L_{\infty} (x_i, x_j) = \max\limits_l |x_i^{(l)}-x_j^{(l)}|$

## 1.3 $k$ 值的选择
- 在应用中，$ k$值一般取一个比较小的数值。 通常采用交叉验证法来选取最优的$k$值.





